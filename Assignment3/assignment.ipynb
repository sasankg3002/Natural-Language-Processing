{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.corpus import semcor\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(synset1, synset2):\n",
    "    meaning1 = synset1.definition()\n",
    "    meaning2 = synset2.definition()\n",
    "    set1 = meaning1.lower()\n",
    "    set2 = meaning2.lower()\n",
    "    s1List = set1.split(\" \")\n",
    "    s2List = set2.split(\" \")\n",
    "    count = 0\n",
    "    for i in s1List:\n",
    "        if (i in s2List):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_data = semcor.tagged_sents(tag = \"sem\")\n",
    "pos_data = semcor.tagged_sents(tag = \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n"
     ]
    }
   ],
   "source": [
    "finalWords = []\n",
    "finalTags = []\n",
    "finalSenses = []\n",
    "\n",
    "totalSentences = 37176\n",
    "\n",
    "for i in range(totalSentences):\n",
    "    if (i%500 == 0):\n",
    "        print(i)\n",
    "    sent = sem_data[i]\n",
    "    wordListInSentence = []\n",
    "    posTagsInSentence = []\n",
    "    sensesInSentence = []\n",
    "    for j in range(len(sent)):\n",
    "        if (isinstance(sent[j], nltk.tree.Tree) and isinstance(sent[j].label(), nltk.corpus.reader.wordnet.Lemma)):\n",
    "            if (len(pos_data[i][j]) == 1):\n",
    "                word = pos_data[i][j][0]\n",
    "                wordListInSentence.append(word)\n",
    "                posTagsInSentence.append(pos_data[i][j].label())\n",
    "                sensesInSentence.append(sent[j].label().synset())\n",
    "\n",
    "    finalWords.append(wordListInSentence)\n",
    "    finalTags.append(posTagsInSentence)\n",
    "    finalSenses.append(sensesInSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "matching = 0\n",
    "for index in range(len(finalWords)):\n",
    "    if (index%500 == 0 and index > 0):\n",
    "        print(index, \"Accuracy so far : \", matching/total)\n",
    "    sentence_words = finalWords[index]\n",
    "    num_synsets = []\n",
    "    synset_to_index_maps = []\n",
    "    all_synsets = []\n",
    "\n",
    "    N = 0\n",
    "\n",
    "    for i in sentence_words:\n",
    "        synsets = wn.synsets(i)\n",
    "        for synset in synsets:\n",
    "            all_synsets.append(synset)\n",
    "        wordmap = {}\n",
    "        for i_dx, synset in enumerate(synsets):\n",
    "            wordmap[synset] = i_dx\n",
    "        synset_to_index_maps.append(wordmap)\n",
    "\n",
    "        num_synsets.append(len(synsets))\n",
    "        N += len(synsets)\n",
    "\n",
    "    P = np.zeros((N, N))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if (j != i):\n",
    "                P[i][j] = similarity(all_synsets[i], all_synsets[j])\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if (np.sum(P[j]) > 0):\n",
    "                P[i][j] = P[i][j]/np.sum(P[j])\n",
    "\n",
    "    num_iter = 100\n",
    "    beta = 0.85\n",
    "\n",
    "    original_prob = np.ones((N, 1))/N\n",
    "    final_prob = original_prob\n",
    "    for i in range(num_iter):\n",
    "        final_prob = np.matmul(P, final_prob)\n",
    "        final_prob = beta*final_prob + (1-beta)/N\n",
    "        final_prob = final_prob/np.linalg.norm(final_prob)\n",
    "\n",
    "    final_prob = np.reshape(final_prob, (N, ))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(sentence_words)):\n",
    "        pos_of_word = finalTags[index][i]\n",
    "        # print(pos_of_word)\n",
    "        if (pos_of_word == \"NN\" or pos_of_word == \"NNP\" or pos_of_word == \"NNS\"):\n",
    "            total += 1\n",
    "            if (num_synsets[i] > 0):\n",
    "                idx = np.argmax(final_prob[count : count + num_synsets[i]])\n",
    "                sense_synset = all_synsets[count + idx]\n",
    "                # print(sentence_words[i], sense_synset, finalSenses[index][i])\n",
    "                if (sense_synset == finalSenses[index][i]):\n",
    "                    matching += 1\n",
    "        count += num_synsets[i]\n",
    "    print(matching, total, matching/total)\n",
    "\n",
    "print(total, matching)\n",
    "print(matching/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_senses_list = []\n",
    "for i in finalSenses:\n",
    "    for j in i:\n",
    "        all_senses_list.append(j)\n",
    "\n",
    "all_senses_set = set(all_senses_list)\n",
    "total_unique_senses = len(all_senses_set)\n",
    "\n",
    "sense_to_index = {}\n",
    "index_to_sense = {}\n",
    "count = 0\n",
    "for i in all_senses_set:\n",
    "    sense_to_index[i] = count\n",
    "    index_to_sense[count] = i\n",
    "    count += 1\n",
    "\n",
    "confusion_matrix = np.zeros((total_unique_senses, total_unique_senses), dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Accuracy so far :  0.4036894036894037\n",
      "1000 Accuracy so far :  0.40994254309268047\n",
      "1500 Accuracy so far :  0.4071394873407769\n",
      "2000 Accuracy so far :  0.41194932000464957\n",
      "2500 Accuracy so far :  0.41501441961067054\n",
      "3000 Accuracy so far :  0.42273675127633564\n",
      "3500 Accuracy so far :  0.4281849335658029\n",
      "4000 Accuracy so far :  0.4369287964062581\n",
      "4500 Accuracy so far :  0.44340276174202187\n",
      "5000 Accuracy so far :  0.43656376727633867\n",
      "5500 Accuracy so far :  0.43777876895628903\n",
      "6000 Accuracy so far :  0.43916476574837693\n",
      "6500 Accuracy so far :  0.4384251436296046\n",
      "7000 Accuracy so far :  0.4379443031370247\n",
      "7500 Accuracy so far :  0.43861398479371805\n",
      "8000 Accuracy so far :  0.4375836530739716\n",
      "8500 Accuracy so far :  0.43670067538439433\n",
      "9000 Accuracy so far :  0.43567681589830415\n",
      "9500 Accuracy so far :  0.43522224000853743\n",
      "10000 Accuracy so far :  0.4345574144092816\n",
      "10500 Accuracy so far :  0.434040940106141\n",
      "11000 Accuracy so far :  0.43502382989123795\n",
      "11500 Accuracy so far :  0.4354790453614416\n",
      "12000 Accuracy so far :  0.435384850669638\n",
      "12500 Accuracy so far :  0.43622289733239\n",
      "13000 Accuracy so far :  0.43698281349458945\n",
      "13500 Accuracy so far :  0.4372177573670111\n",
      "14000 Accuracy so far :  0.4359355774704791\n",
      "14500 Accuracy so far :  0.435260156305006\n",
      "15000 Accuracy so far :  0.4340708850620745\n",
      "15500 Accuracy so far :  0.43383095745874956\n",
      "16000 Accuracy so far :  0.4333635957960823\n",
      "16500 Accuracy so far :  0.4329066398628274\n",
      "17000 Accuracy so far :  0.4323109697376485\n",
      "17500 Accuracy so far :  0.4318960306266371\n",
      "18000 Accuracy so far :  0.431495215988224\n",
      "18500 Accuracy so far :  0.43169596834861107\n",
      "19000 Accuracy so far :  0.4310983134512546\n",
      "19500 Accuracy so far :  0.43107424640906333\n",
      "20000 Accuracy so far :  0.4314273545227067\n",
      "20500 Accuracy so far :  0.43152201291212067\n",
      "21000 Accuracy so far :  0.43152201291212067\n",
      "21500 Accuracy so far :  0.43152201291212067\n",
      "22000 Accuracy so far :  0.43152201291212067\n",
      "22500 Accuracy so far :  0.43152201291212067\n",
      "23000 Accuracy so far :  0.43152201291212067\n",
      "23500 Accuracy so far :  0.43152201291212067\n",
      "24000 Accuracy so far :  0.43152201291212067\n",
      "24500 Accuracy so far :  0.43152201291212067\n",
      "25000 Accuracy so far :  0.43152201291212067\n",
      "25500 Accuracy so far :  0.43152201291212067\n",
      "26000 Accuracy so far :  0.43152201291212067\n",
      "26500 Accuracy so far :  0.43152201291212067\n",
      "27000 Accuracy so far :  0.43152201291212067\n",
      "27500 Accuracy so far :  0.43152201291212067\n",
      "28000 Accuracy so far :  0.43152201291212067\n",
      "28500 Accuracy so far :  0.43152201291212067\n",
      "29000 Accuracy so far :  0.43152201291212067\n",
      "29500 Accuracy so far :  0.43152201291212067\n",
      "30000 Accuracy so far :  0.43152201291212067\n",
      "30500 Accuracy so far :  0.43152201291212067\n",
      "31000 Accuracy so far :  0.43152201291212067\n",
      "31500 Accuracy so far :  0.43152201291212067\n",
      "32000 Accuracy so far :  0.43152201291212067\n",
      "32500 Accuracy so far :  0.43152201291212067\n",
      "33000 Accuracy so far :  0.43152201291212067\n",
      "33500 Accuracy so far :  0.43152201291212067\n",
      "34000 Accuracy so far :  0.43152201291212067\n",
      "34500 Accuracy so far :  0.43152201291212067\n",
      "35000 Accuracy so far :  0.43152201291212067\n",
      "35500 Accuracy so far :  0.43152201291212067\n",
      "36000 Accuracy so far :  0.43152201291212067\n",
      "36500 Accuracy so far :  0.43152201291212067\n",
      "37000 Accuracy so far :  0.43152201291212067\n",
      "32551 75433\n",
      "Accuracy 0.43152201291212067\n",
      "Precision 0.6694740187509932\n",
      "Recall 0.7519186150276638\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "matching = 0\n",
    "true = []\n",
    "predicted = []\n",
    "for index in range(len(finalWords)):\n",
    "    if (index%500 == 0 and index > 0):\n",
    "        print(index, \"Accuracy so far : \", matching/total)\n",
    "    sentence_words = finalWords[index]\n",
    "    num_synsets = []\n",
    "    synset_to_index_maps = []\n",
    "    all_synsets = []\n",
    "\n",
    "    N = 0\n",
    "\n",
    "    for i in sentence_words:\n",
    "        synsets = wn.synsets(i)\n",
    "        for synset in synsets:\n",
    "            all_synsets.append(synset)\n",
    "        wordmap = {}\n",
    "        for i_dx, synset in enumerate(synsets):\n",
    "            wordmap[synset] = i_dx\n",
    "        synset_to_index_maps.append(wordmap)\n",
    "\n",
    "        num_synsets.append(len(synsets))\n",
    "        N += len(synsets)\n",
    "\n",
    "    D = nx.DiGraph()\n",
    "\n",
    "    count = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i):\n",
    "            if (j != i):\n",
    "                D.add_weighted_edges_from([(i, j, similarity(all_synsets[i], all_synsets[j]))])\n",
    "\n",
    "    final_prob = nx.pagerank(D)\n",
    "    final_prob = np.array([final_prob[key] for key in final_prob.keys()])\n",
    "\n",
    "    count = 0\n",
    "    if (len(final_prob) > 0):\n",
    "        for i in range(len(sentence_words)):\n",
    "            pos_of_word = finalTags[index][i]\n",
    "            if (num_synsets[i] > 0):\n",
    "                if (pos_of_word == \"NN\" or pos_of_word == \"NNS\" or pos_of_word == \"NNP\"):\n",
    "                    total += 1\n",
    "                    idx = np.argmax(final_prob[count : count + num_synsets[i]])\n",
    "                    sense_synset = all_synsets[count + idx]\n",
    "                    true.append(finalSenses[index][i])\n",
    "                    predicted.append(sense_synset)\n",
    "                    if (sense_synset == finalSenses[index][i]):\n",
    "                        matching += 1\n",
    "            count += num_synsets[i]\n",
    "\n",
    "print(matching, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.43152201291212067\n",
      "Precision 0.6694740187509932\n",
      "Recall 0.7519186150276638\n",
      "F1-Score 0.7083053127101547\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\", matching/total)\n",
    "print(\"Precision\", nltk.precision(set(true), set(predicted)))\n",
    "print(\"Recall\", nltk.recall(set(true), set(predicted)))\n",
    "print(\"F1-Score\", nltk.f_measure(set(true), set(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent sense (Wordnet First Sense) : 0.4915068126915622\n"
     ]
    }
   ],
   "source": [
    "new_total = 0\n",
    "new_matching = 0\n",
    "\n",
    "for index in range(len(finalWords)):\n",
    "    sentence = finalWords[index]\n",
    "    for i in range(len(sentence)):\n",
    "        pos_of_word = finalTags[index][i]\n",
    "        # if (pos_of_word == \"NN\" or pos_of_word == \"NNS\" or pos_of_word == \"NNP\"):\n",
    "        if (len(wn.synsets(sentence[i])) > 0):\n",
    "            if (wn.synsets(sentence[i])[0] == finalSenses[index][i]):\n",
    "                new_matching += 1\n",
    "        new_total += 1\n",
    "print(\"Most Frequent sense (Wordnet First Sense) :\", new_matching/new_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a sentence : \n",
      "I went to the bank to deposit some money, but it was closed today\n",
      "bank Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
      "today Synset('today.n.01') the present time or age\n"
     ]
    }
   ],
   "source": [
    "print(\"Input a sentence : \")\n",
    "sentence = input()\n",
    "print(sentence)\n",
    "\n",
    "sentence_words = sentence.split()\n",
    "tagged_sentence = nltk.pos_tag(sentence_words)\n",
    "num_synsets = []\n",
    "synset_to_index_maps = []\n",
    "all_synsets = []\n",
    "\n",
    "N = 0\n",
    "\n",
    "for i in sentence_words:\n",
    "    synsets = wn.synsets(i)\n",
    "    for synset in synsets:\n",
    "        all_synsets.append(synset)\n",
    "    wordmap = {}\n",
    "    for i_dx, synset in enumerate(synsets):\n",
    "        wordmap[synset] = i_dx\n",
    "    synset_to_index_maps.append(wordmap)\n",
    "\n",
    "    num_synsets.append(len(synsets))\n",
    "    N += len(synsets)\n",
    "\n",
    "D = nx.DiGraph()\n",
    "\n",
    "count = 0\n",
    "for i in range(N):\n",
    "    for j in range(i):\n",
    "        if (j != i):\n",
    "            D.add_weighted_edges_from([(i, j, similarity(all_synsets[i], all_synsets[j]))])\n",
    "\n",
    "final_prob = nx.pagerank(D)\n",
    "final_prob = np.array([final_prob[key] for key in final_prob.keys()])\n",
    "\n",
    "count = 0\n",
    "if (len(final_prob) > 0):\n",
    "    for i in range(len(sentence_words)):\n",
    "        pos_of_word = tagged_sentence[i][1]\n",
    "        if (num_synsets[i] > 0):\n",
    "            if (pos_of_word == \"NN\" or pos_of_word == \"NNS\" or pos_of_word == \"NNP\"):\n",
    "                idx = np.argmax(final_prob[count : count + num_synsets[i]])\n",
    "                sense_synset = all_synsets[count + idx]\n",
    "                print(sentence_words[i], sense_synset, sense_synset.definition())\n",
    "\n",
    "        count += num_synsets[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
